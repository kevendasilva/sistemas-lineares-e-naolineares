<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="stylesheet/style.css">

    <!-- Inserindo LaTex Code -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript"
      src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

    <!-- Chart.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.6.0/Chart.min.js"></script>

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous">

    <title>Trabalho 2 - Sistemas lineares e não-lineares</title>
  </head>
  <body>

    <section class="container py-3 bg-warning" id="begin">
      <div class="row justify-content-center">
        <div class="col-lg-1 text-center">
          <img src="img/logo-ufc.PNG" class="img-fluid">
        </div>
        <div class="col-lg-12 text-center pb-3">
          <p>
            <h5><strong>Universidade Federal do Ceará <br>
              Centro de Tecnologia <br>
              Departamento de Engenharia de Teleinformática <br>
              Curso de graduação em Engenharia de Computação <br></strong></h5>
          </p>
        </div>
        <div class="col-lg-12 text-center">
          <p>
            <h5><strong>Trabalho 2 - Resolução de Sistemas Lineares e Não-Lineares <br>
              <br>
              Keven da Silva Gonçalves</strong></h5>
          </p>
        </div>
      </div>
    </section>

    <section class="container py-4">
      <div class="row justify-content-center">
        <div class="col-lg-12 text-center">
          <h3><strong>Sumário</strong></h3>
        </div>
        <div class="col-lg-12 px-5">
          <ol>
            <li><a href="#introdução">Introdução</a></li>
            <li><a href="#desenvolvimento">Desenvolvimento</a></li>
            <ol>
              <li><a href="#diretos">Métodos diretos</a></li>
              <li><a href="#iterativos">Métodos iterativos</a></li>
            </ol>
            <li><a href="#resultados">Resultados</a></li>
            <ol>
              <li><a href="#gauss">Método de eliminação de Gauss</a></li>
              <li><a href="#jacobi">Método de Jacobi</a></li>
              <li><a href="#gauss_seidel">Método de Gauss-Seidel</a></li>
            </ol>
            <li><a href="#conclusão">Conclusão</a></li>
          </ol>
        </div>
      </div>
    </section>
    
    <section class="container py-4" id="introdução">
      <div class="row">
        <div class="col-lg-12">
          <h2><strong>1. Introdução</strong></h2>
          <p>Um sistema de equações lineares é utilizado para descrever problemas que ocorrem na engenharia, ciência,
            negócios, economia, etc. Um sistema de $n$ equações lineares tem a seguinte forma:
            $$a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1$$
            $$a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2$$
            $$a_{31}x_1 + a_{32}x_2 + \cdots + a_{3n}x_n = b_3$$
            $$\vdots$$
            $$a_{n1}x_1 + a_{n2}x_2 + \cdots + a_{nn}x_n = b_n$$
            <br>
            E, na forma matricial é dado como $[a][x] = [b]$, ou ainda
            $$
            \left[
            \begin{array}{ccccc}
            a_{11} & a_{12} & a_{13} & \cdots & a_{1n} \\
            a_{21} & a_{22} & a_{23} & \cdots & a_{2n} \\
            a_{31} & a_{32} & a_{33} & \cdots & a_{3n} \\
            \vdots & \vdots & \vdots & \ddots & \vdots \\
            a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn} 
            \end{array}
            \right]
            \left[
            \begin{array}{c}
            x_1 \\
            x_2 \\
            x_3 \\
            \vdots \\
            x_n
            \end{array}
            \right]

            =

            \left[
            \begin{array}{c}
            b_1 \\
            b_2 \\
            b_3 \\
            \vdots \\
            b_n
            \end{array}
            \right]
            $$
            Existem dois tipos de métodos numéricos, <a href="#diretos">diretos</a> e <a href="#iterativos">iterativos</a>, que são
            utilizados para solucionar sistemas de equações lineares. Nos métodos diretos, a solução é obtida a partir do 
            uso de operações algébricas nas equações. E, nos métodos iterativos, uma solução inicial é escolhida e, utilizada
            em um processo iterativo para estimar uma nova solução mais precisa.</p>
        </div>
      </div>
    </section>

    <section class="container py-4" id="desenvolvimento">
      <div class="row">
        <div class="col-lg-12">
          <h2><strong>2. Desenvolvimento</strong></h2>
        </div>
        <div class="col-lg-12 px-5" id="diretos">
          <h3><strong>2.1 Métodos diretos</strong></h3>
          <h5><i>2.1.1 Método de eliminação de Gauss</i></h5>
          <p>
            Neste procedimento, o sistema de equações lineares é manipulado algebricamente, até que apresente  a forma
            de uma matriz triangular superior. Esta matriz é então resolvida com o uso da substituição regressiva. O 
            procedimento para determinar a matriz triangular superior é bem simples, e de fácil programação em um 
            computador. A primeira equação (<strong>equação pivô</strong>) do sistema não é alterada e os termos das 
            demais equações que incluem a variável $x_1$, são eliminados. De modo que, o único coeficiente diferente de 
            zero, na coluna 1, seja o coeficiente $a_{11}$. O coeficiente $a_{11}$ é chamado de <strong>coeficiente pivô</strong>.
            Para eliminar os coeficientes abaixo do coeficiente pivô, realizamos a seguinte operação: 
            $$L_i - m_{i1}L_1$$
            onde $L_i$ é uma linha, abaixo da linha pivô, da matriz estendida que descreve o sistema de equações lineares. 
            E, o coeficiente $m_{i1} = a_{i1}/a_{11}$. A linha $L_i$ é então substituída pelo resultado da operação acima.
            Este processo é repetido para as demais linhas, zerando então, os coeficientes abaixo dos coeficientes pivô $a_{ii}$.
            De modo geral, para uma linha $j$ cujo elemento pivô é $a_{jj}$, os coeficientes abaixo do coeficiente pivô serão zerados
            com a operação:
            $$L_i = L_i - m_{ij}L_j$$
            onde $j = 1, 2, \cdots, n - 1$ e $i = j + 1, j + 2, ..., n$.
            O resultado é uma matriz da forma:

            $$
            \left[
            \begin{array}{cccccc}
            a_{11} & a_{12} & a_{13}& \cdots & a_{1n} & b_1 \\
            0 & a'_{22} & a'_{23} & \cdots & a'_{2n} & b'_2 \\ 
            0 & 0 & a'_{33} & \cdots & a'_{3n} & b'_3 \\ 
            \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
            0 & 0 & 0 & \cdots & a'_{nn} & b'_n \\ 
            \end{array}
            \right]
            $$

            <br>
            No método de eliminação de Gauss, o número de operações algébricas realizadas com as linhas é dado por:
            $$\sum\limits_{i = 1}^{n - 1}(n-i)$$
            e com a substituição regressiva, utilizada para determinar os valores das incógnitas, temos mais $n$ iterações.
            Portanto, o total de iterações é dado por:
            $$t(n) = n + \sum\limits_{i = 1}^{n - 1}(n-i)$$
            simplificando, temos
            $$t(n) = n + \sum\limits_{i = 1}^{n - 1}(n) - \sum\limits_{i = 1}^{n - 1}(i) = n + n(n - 1) - \frac{n(n-1)}{2} = n^2 - \frac{n(n-1)}{2}$$
            logo
            $$t(n) = \frac{n(n + 1)}{2}$$
            Este método pode apresentar algumas dificuldades com a sua aplicação. A primeira dificuldade é encontrada quando um dos
            elementos pivô é igual a zero, pois no processo de substituição das linhas, dividimos a linha pivô pelo coeficiente pivô e,
            caso o coeficiente seja igual a zero, essa divisão é impossível. E a segunda dificuldade, é encontrada quando um dos elementos
            pivô é pequeno em relação aos demais coeficientes da linha pivô. Os dois problemas podem ser resolvidos com o uso de uma simples técnica,
            que é chamada de pivotação. Que consiste, basicamente, em alterar a ordem das linhas ou equações. De modo que, os coeficientes pivô
            sejam diferentes de zero e que sejam os maiores possíveis.
          </p>
          <div class="col-lg-12">
            <h5><i>2.1.2 Fluxograma para o método de eliminação de Gauss</i></h5>
            <p>
              Fluxograma desenhado com base no pseudocódigo do método de eliminação de Gauss.
            </p>
            <div class="col-lg-12 text-center">
              <img src="../Fluxogramas/MétodoDeEliminaçãoDeGauss.png" style="width: 50%;">
            </div>
          </div>
          <div class="col-lg-12 py-3">
            <h5><i>2.1.3 Pseudocódigo para o método de eliminação de Gauss</i></h5>
            <div class="col-lg-10 code">
              <pre>
                <code>
    1.  /* 
    2.   * Pseudocódigo para o método de eliminação de Gauss
    3.   * 
    4.   * 'matrix' é a matriz de entrada 
    5.   *
    6.   * Matriz escolhida (estendida)
    7.   * m = [[ 4,  -2,   -3,   6,   12], # Matriz estendida
    8.   *      [-6,   7,  6.5,  -6, -6.5],
    9.   *      [ 1, 7.5, 6.25, 5.5,   16],
    10.  *      [-12, 22, 15.5,  -1,   17] ]
    11.  * 
    12.  * 'matrix_gauss' é a matrix de saída
    13.  * uma matriz triangular superior
    14.  *
    15.  *
    16.  * 
    17.  */
    18.  
    19.  Inicio algoritmo
    20.  
    21.    // Método de eliminação de Gauss
    22.    FUNÇÃO gauss(matrix)
    23.      // Criando uma copia do parâmetro de entrada
    24.      matrix_gauss = FAÇA_UMA_CÓPIA_DE(matrix) 
    25.      // A eliminação começa na "linha 1" (que na verdade é a linha 2)
    26.      line = 1
    27.      // Coluna inicial
    28.      a = 0
    29.      // Percorrendo (n - 1) linhas da matriz. Começando a partir da segunda linha.
    30.      PARA (matrix_gauss.num_of_lines - 1) VEZES FAÇA
    31.        // "Salvando" o número da linha
    32.        line_before = line
    33.        // Número de linhas que serão utilizadas nas operações.
    34.        num_of_interations = matrix_gauss.num_of_lines - line
    35.        PARA num_of_interations VEZES FAÇA
    36.          Line_line = Line_line - m_{linea a} * Line_a
    37.          // Mudando para a próxima linha
    38.          line += 1
    39.        FIM PARA
    40.        // Linha retorna para a posição inicial mais 1.
    41.        line = line_before + 1
    42.        // Mudando de coluna
    43.        a += 1
    44.      FIM PARA
    45.      // Retornando o resultado
    46.      matrix_gauss
    47.    FIM FUNÇÃO
    48.  
    49.  Fim algoritmo
                </code>
              </pre>
            </div>
          </div>
        </div>
        
        <div class="col-lg-12 px-5" id="iterativos">
          <h3><strong>2.2 Métodos iterativos</strong></h3>
          <p>
            Em métodos iterativos, as soluções de sistemas são encontradas a partir da forma explícita das equações, onde
            cada incógnita é escrita em termos das demais incógnitas. O primeiro passo é escolher uma solução inicial, esta
            é utilizada para determinar a próxima solução. Caso a nova solução não seja suficientemente precisa, será necessário
            utiliza-la para determinar uma nova solução. O processo é repetido até que a solução encontrada seja satisfatória.
            <br>
            Para um sistema de $n$ equações lineares, uma condição suficiente para que a solução convirja é dada por:
            $$|a_{ii}| > \sum\limits_{j\ =\ 1,\ j\ \neq \ i}^{j\ =\ n}|a_{ij}|$$
            onde $a$ é um elemento da matriz de coeficientes $[a]$. Essa condição é suficiente para que a solução convirja. 
            No entanto, não é necessária para a convergência do método iterativo.
          </p>
          <h5><i>2.2.1 Método de Jacobi</i></h5>
          <p>
            No método de Jacobi, o primeiro passo é determinar uma solução inicial, caso não se tenha nenhuma informação a respeito do sistema,
            assumimos que todas as incógnitas são iguais a zero. A segunda estimativa de solução $x_1^{(2)}, x_2^{(2)}, \cdots, x_n^{(2)}$ é dada
            por: 
            $$x_i^{(2)} = \frac{1}{a_{ii}} \left[ b_i\ - \sum\limits_{j\ =\ 1}^{n} a_{ij}x_j^{(1)}\right]$$
            com $j \neq i$ e $i = 1, 2, 3, \cdots, n$.
            De modo geral, temos que a (k + 1)-ésima estimativa é encontrada a partir da k-ésima estimativa, usando a seguinte fórmula:
            $$x_i^{(k + 1)} = \frac{1}{a_{ii}} \left[ b_i\ - \sum\limits_{j\ =\ 1}^{n} a_{ij}x_j^{(k)} \right]$$
            onde $j \neq i$ e $i = 1, 2, 3, \cdots, n$. As iterações são realizadas até que o valor absoluto do erro relativo estimado, de cada
            uma das variáveis, seja menor que um determinado valor. Ou seja, quando
            $$\left| \frac{x_i^{(k + 1)} - x_i^{(k)}}{x_i^{(k)}}\right| < e$$
            onde $e$ é o valor escolhido e o índice $i = 1, 2, 3, \cdots, n$. 
          </p>
          <div class="col-lg-12">
            <h5><i>2.2.2 Fluxograma para o método de Jacobi</i></h5>
            <p>
              Fluxograma desenhado com base no pseudocódigo do método de Jacobi. 
            </p>
            <div class="col-lg-12 text-center">
              <img src="../Fluxogramas/MétodoDeJacobi.png" style="width: 80%;">
            </div>
          </div>
          <div class="col-lg-12">
            <h5><i>2.2.3 Pseudocódigo para o método de Jacobi</i></h5>
            <div class="col-lg-10 code">
              <pre>
                <code>
    1.  /* Matriz escolhida (estendida)
    2.   * m = [[ 8,   -4,    0, -1,    0,    0,  20],
    3.   *      [ 0, -2.5,  4.5,  0,    0,   -2,  14],
    4.   *      [ 0,   -5,    0, -2,  8.5, -1.5, -30],
    5.   *      [-4, 11.5, -2.5,  0,   -5,    0, -12],
    6.   *      [-1,    0,    0,  3,   -2,    0,   8],
    7.   *      [ 0,    0,   -2,  0, -1.5,    8,   0]]
    8.   * 
    9.   * Solução numérica estimada
    10.  * (como não possuo nenhuma estimativa inicial, todas as incógnitas são iguais a zero)
    11.  * initial_solution = [0, 0, 0, 0, 0, 0]
    12.  *
    13.  * Erro escolhido (e) = 0.03
    14.  * 
    15.  * A variável 'ite' foi utilizada com contador de iterações
    16.  * Quando o método 'jacobi' é chamado, ite = 0
    17.  */
    18.
    19.  Inicio algoritmo
    20.
    21.    FUNÇÃO err_x_i(initial_solution, next_solution)
    22.      // Vetor inicialmente vazio
    23.      err_x_i = []
    24.      // Percorrendo cada incógnita
    25.      num_of_interations = tamanho_de(initial_solution)
    26.      // A variável 'i' varia de 0 até (num_of_interations - 1)
    27.      PARA num_of_interations VEZES, FAÇA |i|
    28.        // Caso o erro relativo estimado seja menor que 'e' (e = 0.000001)
    29.        SE ((next_solution[i] - initial_solution[i]) / initial_solution[i]).abs < 0.000001
    30.          // Caso o erro da incógnita seja menor que o erro escolhido, o vetor recebe o valor lógico "true"
    31.          err_x_i.push(true)
    32.        SENÃO
    33.          err_x_i.push(false) # Caso contrário, recebe "false"
    34.        FIM SE
    35.      FIM PARA
    36.      RETORNE err_x_i
    37.    FIM FUNÇÃO
    38.
    39.    FUNÇÃO jacobi(initial_solution, matrix, ite)
    40.      // Contandor de iterações
    41.      ite = ite + 1
    42.      // Vetor que conterá a próxima solução (inicialmente vazio)
    43.      next_solution = []
    44.      n = matrix.num_of_lines - 1
    45.      // A variável 'i' varia de 0 a n, ou seja, de 0 a matrix.num_of_lines - 1
    46.      PARA CADA VALOR NO RANGE (0..n) FAÇA |i|
    47.        next_solution.push((b_i(matrix, i) - sum(initial_solution, matrix, i, n)) / a_ij(matrix, i, i).to_f)
    48.      FIM PARA CADA
    49.
    50.      // Calculando o erro de cada uma das incógnitas com a FUNÇÃO 'err_x_i'
    51.      err_x_i = err_x_i(initial_solution, next_solution)
    52.      // Caso o erro de uma das variáveis não atenda a condição estabelecida.
    53.      SE err_x_i CONTÉM false 
    54.        // Uma nova iteração é iniciada.
    55.        jacobi(next_solution, matrix, ite)
    56.      SENÃO
    57.        // Caso a solução encontrada seja satisfatória
    58.        // Retornando a solução estimada e o número de iterações
    59.        RETORNE [next_solution, ite]
    60.      FIM SE
    61.    FIM FUNÇÃO
    62.
    63.  Fim algoritmo
                </code>
              </pre>
            </div>
          </div>
        
          <h5><i>2.2.4 Método de Gauss-Seidel</i></h5>
          <p>
            No método de Gauss-Seidel, assumimos valores iniciais para as variáveis $x_2, x_3, x_4, \cdots, x_n$. A partir
            destes determinamos o valor de $x_1$. O valor de $x_1$ e os demais valores, escolhidos como solução inicial, são utilizados
            para determinar o próximo valor da incógnita ($x_2$). Este processo é repetido até $x_n$. Diferentemente do método de Jacobi,
            onde os novos valores estimados para as incógnitas são utilizados apenas na próxima estimativa de solução, no método de Gauss-Seidel
            o novo valor de uma incógnita é utilizado para determinar os valores das próximas variáveis. Ou seja, a medida que o valor de
            uma incógnita é calculado, ele é imediatamente utilizado para determinar os demais valores.
            <br>
            A aplicação da equação
            $$x_i^{(k + 1)} = \frac{1}{a_{ii}} \left[ b_i\ - \sum\limits_{j\ =\ 1}^{n} a_{ij}x_j^{(k)} \right]$$
            no método de Gauss-Seidel, leva à formula iterativa:
            $$x_i^{(k + 1)} = \frac{1}{a_{ii}} \left[ b_i\ - \left(\sum\limits_{j\ =\ 1}^{i - 1} a_{ij}x_j^{(k + 1)} +\sum\limits_{j\ =\ i + 1}^{n} a_{ij}x_j^{(k)}\right)\right]$$
            com $i = 2, 3, \cdots, n - 1$. O critério de parada é o mesmo utilizado para o método de Jacobi.
          </p>
          <div class="col-lg-12">
            <h5><i>2.2.5 Fluxograma para o método de Gauss-Seidel</i></h5>
            <p>
              Fluxograma desenhado com base no pseudocódigo do método de Gauss-Seidel. 
            </p>
            <div class="col-lg-12 text-center">
              <img src="../Fluxogramas/MétodoDeGaussSeidel.png" style="width: 80%;">
            </div>
          </div>
          <div class="col-lg-12">
            <h5><i>2.2.6 Pseudocódigo para o método de Gauss-Seidel</i></h5>
            <div class="col-lg-10 code">
              <pre>
                <code>
    1.  /* Matriz escolhida (estendida)
    2.   * m = [[ 8,   -4,    0, -1,    0,    0,  20],
    3.   *      [ 0, -2.5,  4.5,  0,    0,   -2,  14],
    4.   *      [ 0,   -5,    0, -2,  8.5, -1.5, -30],
    5.   *      [-4, 11.5, -2.5,  0,   -5,    0, -12],
    6.   *      [-1,    0,    0,  3,   -2,    0,   8],
    7.   *      [ 0,    0,   -2,  0, -1.5,    8,   0]]
    8.   * 
    9.   * Solução numérica estimada
    10.  * (como não possuo nenhuma estimativa inicial, todas as incógnitas são iguais a zero)
    11.  * initial_solution = [0, 0, 0, 0, 0, 0]
    12.  *
    13.  * Erro escolhido (e) = 0.03
    14.  * 
    15.  * A variável 'ite' foi utilizada com contador de iterações
    16.  * Quando o método 'gauss_seidel' é chamado, ite = 0
    17.  */
    18.
    19.  Inicio algoritmo
    20.
    21.    FUNÇÃO err_x_i(initial_solution, next_solution)
    22.      // Vetor inicialmente vazio
    23.      err_x_i = []
    24.      // Percorrendo cada incógnita
    25.      num_of_interations = tamanho_de(initial_solution)
    26.      // A variável 'i' varia de 0 até (num_of_interations - 1)
    27.      PARA num_of_interations VEZES, FAÇA |i|
    28.        // Caso o erro relativo estimado seja menor que 'e' (e = 0.000001)
    29.        SE ((next_solution[i] - initial_solution[i]) / initial_solution[i]).abs < 0.000001
    30.          // Caso o erro da incógnita seja menor que o erro escolhido, o vetor recebe o valor lógico "true"
    31.          err_x_i.push(true)
    32.        SENÃO
    33.          err_x_i.push(false) # Caso contrário, recebe "false"
    34.        FIM SE
    35.      FIM PARA
    36.      RETORNE err_x_i
    37.    FIM FUNÇÃO
    38.
    39.    FUNÇÃO gauss_seidel(initial_solution, matrix, ite)
    40.      // Contandor de iterações
    41.      ite = ite + 1
    42.      // Vetor que conterá a próxima solução (inicialmente vazio)
    43.      next_solution = FAÇA_UMA_CÓPIA_DE(initial_solution)
    44.      n = matrix.num_of_lines - 1
    45.      // A variável 'i' varia de 0 a n, ou seja, de 0 a matrix.num_of_lines - 1
    46.      PARA CADA VALOR NO RANGE (0..n) FAÇA |i|
    47.        next_solution[i] = (b_i(matrix, i) - sum(next_solution, matrix, i, n)) / a_ij(matrix, i, i).to_f
    48.      FIM PARA CADA
    49.      x
    50.      // Calculando o erro de cada uma das incógnitas com a FUNÇÃO 'err_x_i'
    51.      err_x_i = err_x_i(initial_solution, next_solution)
    52.      // Caso o erro de uma das variáveis não atenda a condição estabelecida.
    53.      SE err_x_i CONTÉM false 
    54.        // Uma nova iteração é iniciada.
    55.        gauss_seidel(next_solution, matrix, ite)
    56.      SENÃO
    57.        // Caso a solução encontrada seja satisfatória
    58.        // Retornando a solução estimada e o número de iterações
    59.        RETORNE [next_solution, ite]
    60.      FIM SE
    61.    FIM FUNÇÃO
    62.
    63.  Fim algoritmo
                </code>
              </pre>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="container py-4" id="resultados">
      <div class="row justify-content-center">
        <div class="col-lg-12">
          <h2><strong>3. Resultados</strong></h2>
        </div>
        <div class="col-lg-12 px-5" id="gauss">
         <h3><strong>3.1 Método de eliminação de Gauss</strong></h3>
          <p>
          Os métodos numéricos para solucionar sistemas lineares, abordados nesse trabalho, foram implementados na linguagem de 
          programação Ruby. O primeiro método, o método de eliminação de Gauss, recebeu como matriz de entrada a matriz (estendida) a seguir:
          $$M = 
          \left[ \begin{array}{rrrrr} 
            4 & -2 & -3 & 6 & 12 \\
          -6 & 7 & 6.5 & -6 & -6.5 \\
          1 & 7.5 & 6.25 & 5.5 & 16 \\
          -12 & 22 & 15.5 & -1 & 17
          \end{array}\right]$$
          Esta matriz foi retirada do Exemplo 4.1, do livro "Métodos Numéricos para Engenheiros e Cientistas". Após o procedimento realizado
          pelo método, obtive a seguinte matriz como resultado:
          $$M^´ = 
          \left[ \begin{array}{rrrrr} 
            4 & -2 & -3 & 6 & 12 \\
          0 & 4 & 2 & 3 & 11.5 \\
          0 & 0 & 3 & -2 & -10 \\
          0 & 0 & 0 & 4 & 2
          \end{array}\right]$$
          com o uso da substituição regressiva, encontrei o seguinte vetor solução:
          $$X = 
          \left[
          \begin{array}{r}
          2 \\
          4 \\
          -3 \\
          0.5 \\
          \end{array}
          \right]$$
          Como o método de eliminação de Gauss
           de Gauss não envolve o uso de soluções estimadas, não existe a possibilidade
          de calcularmos erros, pois a solução é exata. No entanto, podemos comparar a eficiência dos métodos a
          partir do números de iterações que cada um utilizou para chegar em uma solução suficientemente precisa.
          Ao utilizar o sistema de equações lineares, descrito pela matriz $M$, nenhum dos métodos iterativos convergiu. Portanto,
          eu "descartei" essa matriz e procurei uma que poderia ser utilizada nos três métodos. A outra matriz utilizada
          foi:
          $$Q = 
          \left[ \begin{array}{rrrrrrr} 
          8 & -4 & 0 & -1 & 0 & 0 & 20 \\
          0 & -2.5 & 4.5 & 0 & 0 & -2 & 14 \\
          0 & -5 & 0 & -2 & 8.5 & -1.5 & -30 \\
          -4 & 11.5 & -2.5 & 0 & -5 & 0 & -12 \\
          -1 & 0 & 0 & 3 & -2 & 0 & 8 \\
          0 & 0 & -2 & 0 & -1.5 & 8 & 0
          \end{array}\right]$$
          Matriz retirada da Questão 4.37, dos exercícios propostos pelo livro "Métodos Numéricos para Engenheiros e Cientistas". A matriz descreve o seguinte sistema linear:
          <div class="row justify-content-center py-3">
            <img src="img/matriz_q.jpg" style="width: 30%;">
          </div>
          As equações foram encontradas a partir da aplicação das Leis de Kirchhoff. Como alguns dos coeficientes pivô são iguais a zero, eu utilizei o processo de pivotação para mudar isso.
          Finalizada a pivotação, utilizei o método de eliminação de Gauss e encontrei o seguinte vetor solução:
          $$X = 
          \left[
          \begin{array}{r}
          1.046970 \\
          -2.757568 \\
          1.268917 \\
          -0.593970 \\
          -5.414441 \\
          -0.697978
          \end{array}
          \right]$$
          Os valores das incógnitas foram arredondados para facilitar a visualização dos números. Como definido anteriormente,
          o número de iterações, em função do número de linhas $n$, é dado por:
          $$t(n) = \frac{n(n + 1)}{2}$$
          para $n\ = 6$, temos:
          $$t(6) = \frac{6(6 + 1)}{2} = 21$$
          Logo, o número de iterações que o método utilizou foi 21.
          </p>
        </div>
        <div class="col-lg-12 px-5" id="jacobi">
          <h3><strong>3.2 Método de Jacobi</strong></h3>
          <p>
            A matriz $Q$ foi utilizada e como solução inicial, assumi que todos as incógnitas são iguais a zero. Para prosseguir, e 
            encontrar uma nova estimativa de solução, utilizei a fórmula:
            $$x_i^{(k + 1)} = \frac{1}{a_{ii}} \left[ b_i\ - \sum\limits_{j\ =\ 1}^{n} a_{ij}x_j^{(k)} \right]$$
            A primeira iteração deste método se encerra quando $i = n$. Neste caso, $i = 6$. O valor escolhido para o erro foi $e = 0.03$.
            E, o método precisou de 25 iterações para que cada uma das incógnitas apresenta-se, o erro relativo estimado, menor que $e$. Ou seja,
            foram necessárias 25 iterações para que a solução convergisse. A seguir, apresento um gráfico contendo o erro relativo estimado,
            de cada uma das incógnitas, a cada iteração.
            <div class="row justify-content-center">
              <div class="col-lg-12 text-center">
                <canvas id="errChartJacobi"></canvas>
              </div>
            </div>
            O resultado encontrado pelo método foi o seguinte:
            $$X = 
            \left[
            \begin{array}{r}
            1.120837 \\
            -2.652208 \\
            1.357991 \\
            -0.483507 \\
            -5.307162 \\
            -0.649281
            \end{array}
            \right]$$
            Como o Erro Relativo Estimado é dado por:
            $$ERE = \left| \frac{x^{(k + 1)} - x^{(k)}}{x^{(k)}} \right|$$
            o erro inicial apresentado pelas incógnitas tende ao infinito, pois assumimos que a solução 
            inicial para as incógnitas são todas iguais a zero. A solução encontrada também foi arredondado para facilitar a visualização dos números. 
            Podemos verificar que o resultado apresentado pelo método, difere da solução exata para o sistema. Este resultado é decorrente da não utilização
            de uma estimativa inicial aproximada da solução real. Outro fator que alterou a precisão da solução, foi a escolha do critério de parada.
            O critério de parada utilizado é que o valor do ERE de cada umas das incógnitas seja menor que $0.03$. Além do valor escolhido como parada, ser relativamente
            alto, o modo como o erro foi calculado também interfere na solução apresentada pelo método.
          </p>
        </div>
        <div class="col-lg-12 px-5" id="gauss_seidel">
          <h3><strong>3.3 Método de Gauss-Seidel</strong></h3>
          <p>
            No método de Gauss-Seidel, a matriz $Q$ foi novamente utilizada. De modo semelhante ao método anterior, assumi
            que todas as incógnita são iguais a zero. Para dar início as iterações, utilizei a fórmula:
            $$x_i^{(k + 1)} = \frac{1}{a_{ii}} \left[ b_i\ - \left(\sum\limits_{j\ =\ 1}^{i - 1} a_{ij}x_j^{(k + 1)} +\sum\limits_{j\ =\ i + 1}^{n} a_{ij}x_j^{(k)}\right)\right]$$
            com $i = 2, 3, \cdots, n - 1$. O critério de parada utilizado é o mesmo para o método de Jacobi. Todas as incógnitas
            devem apresentar o erro relativo estimado, menor que $e$. Este método precisou de 18 iterações para convergir. A seguir, apresento um gráfico contendo o erro relativo estimado,
            de cada uma das incógnitas, a cada iteração.
            <div class="row justify-content-center">
              <div class="col-lg-12 text-center">
                <canvas id="errChartGaussSeidel"></canvas>
              </div>
            </div>
            O resutaldo da implementação do método foi:
            $$X = 
            \left[
            \begin{array}{r}
            1.081722 \\
            -2.714426 \\
            1.301746 \\
            -0.548739 \\
            -5.374902 \\
            -0.682357
            \end{array}
            \right]$$
            o vetor $X$ resultante da implementação do método é mais preciso, quando comparado com o vetor $X$ encontrado pelo método de Jacobi.
          </p>
        </div>
      </div>
    </section>

    <section class="container py-4" id="conclusão">
      <div class="row justify-content-center">
        <div class="col-lg-12">
          <h2><strong>4. Conclusão</strong></h2>
        </div>
        <div class="col-lg-12 px-5">
          <p>
            Apesar dos métodos iterativos não apresentaram a solução exata para o sistema linear em questão, ambos os métodos
            iterativos podem ser utilizados quando o método de eliminação de Gauss não puder ser aplicado. No caso da matriz $M$
            (inicialmente escolhida como a matriz que descreveria o sistema linear deste trabalho) não pode ser utilizada nos métodos
            iterativos, pois as soluções não convergiam. Portanto, foi necessário utilizar uma outra matriz (outro sistema), a fim
            de estabelecer uma comparação na eficiência dos três métodos.
            <br>
            <br>
            A matriz $Q$, foi escolhida e utilizado nos três métodos. O primeiro método, o método de eliminação de Gauss, necessitou
            de apenas 21 iterações para apresentar a solução exata para o sistema. Como o processo não utiliza estimativas de soluções
            para incógnitas, não podemos comparar os erros apresentados pelos métodos. No segundo método, o método de Jacobi, a implementação
            retornou a solução após 25 iterações, onde o critério de parada escolhido foi $ERE < 0.03$ (para cada incógnita). Apesar do valor 
            para erro ser 0.03 (3%), a solução $X$ apresentada pelo método apresenta um erro maior, quando comparada com a solução exata (encontrada
            pelo método de eliminação de Gauss). O erro da solução gira em torno de 7%. Isso se deve ao uso do erro relativo estimado. Por fim, o método de Gauss-Seidel, precisou de 
            apenas 18 iterações para que a solução convergisse. Mesmo utilizando o critério de parada do método de Jacobi, a solução apresentada
            por este método, apresentou menor erro, quando comparada com a solução exata. Neste caso, o erro apresentado pela solução está entre 3% e 4%.
            <br>
            <br>
            Portanto, quando comparamos os três métodos, aquele que apresenta a maior precisão é método de eliminação de Gauss (por apresentar a solução exata).
            No entanto, caso seja tolerável que a solução para o sistema apresente erros, o método de Gauss-Seidel pode ser utilizado (caso a solução convirja), pois,
            entre os três métodos, foi o que apresentou o menor número de iterações. É necessário destacar que, apesar dos métodos de Jacobi e de Gauss-Seidel serem
            similares, a diferença no número de iterações, que cada método precisa para convergir se torna grande, quando a precisão escolhida é alta. Logo, o método 
            de Gauss-Seidel se destaca, por utilizar menos iterações.
          </p>
        </div>
      </div>
    </section>

    <script src="script/script.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/js/bootstrap.bundle.min.js" integrity="sha384-b5kHyXgcpbZJO/tY9Ul7kGkf1S0CWuKcCD38l8YkeH8z8QjE0GmW1gYU5S9FOnJ0" crossorigin="anonymous"></script>
  </body>
</html>